{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UebUIQJNMFnb",
        "outputId": "c8201a52-b5c1-4eaa-8ebc-c83f0ba1d3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langgraph\n",
            "  Using cached langgraph-0.4.5-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.59)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting python-dotenv\n",
            "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.3.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting arxiv\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.69-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.25.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.4.5-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_groq-0.3.2-py3-none-any.whl (15 kB)\n",
            "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.25.0-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: wikipedia, sgmllib3k\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=9df6e73c48f4136b9abbd7473fd3e6d03d68b29b3017422b5103e437467824a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=beeb08afc28ddaf80b27cd2ecbc0f5908a68ae432eaf05ee5107aeb743223a31\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built wikipedia sgmllib3k\n",
            "Installing collected packages: sgmllib3k, python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, feedparser, wikipedia, typing-inspect, arxiv, pydantic-settings, langgraph-sdk, groq, dataclasses-json, langgraph-checkpoint, langchain-groq, langgraph-prebuilt, langgraph, langchain-community\n",
            "Successfully installed arxiv-2.2.0 dataclasses-json-0.6.7 feedparser-6.0.11 groq-0.25.0 httpx-sse-0.4.0 langchain-community-0.3.24 langchain-groq-0.3.2 langgraph-0.4.5 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.69 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.9.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 sgmllib3k-1.0.0 typing-inspect-0.9.0 wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic langchain langgraph langchain-core langchain-community python-dotenv langchain-groq arxiv wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6cjtVb847gT"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = \"Your API key here\"\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"Your API Key here\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Lr3Hm76_pGi"
      },
      "source": [
        "#arXiv\n",
        "Hosting and reading academic research papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNQex9Dc2-C_"
      },
      "outputs": [],
      "source": [
        "## tools\n",
        "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLeAaXZS3pwU",
        "outputId": "95589985-dfa5-42cd-a7e3-42a07e3b42ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arxiv\n"
          ]
        }
      ],
      "source": [
        "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
        "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv,description=\"Query arxiv papers\")\n",
        "print(arxiv.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "collapsed": true,
        "id": "DGk0WSUr4U3X",
        "outputId": "8788a143-1717-459f-80a3-69c68af73eea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Published: 2023-12-23\\nTitle: Human-AI Collaboration in Real-World Complex Environment with Reinforcement Learning\\nAuthors: Md Saiful Islam, Srijita Das, Sai Krishna Gottipati, William Duguay, Clodéric Mars, Jalal Arabneydi, Antoine Fagette, Matthew Guzdial, Matthew-E-Taylor\\nSummary: Recent advances in reinforcement learning (RL) and Human-in-the-Loop (HitL)\\nlearning have made human-AI collaboration easier for humans to team with AI\\nagents. Leveraging human expertise and experience with AI in int'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arxiv.invoke(\"What is latest advancement in Agentic AI systems\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBoSzy1uAVME"
      },
      "source": [
        "#Wikipedia\n",
        "\n",
        " retrieve background knowledge, summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7OVhCCx4dlU",
        "outputId": "f1eae1f2-accf-40aa-af11-aa647b572d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wikipedia\n"
          ]
        }
      ],
      "source": [
        "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
        "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
        "print(wiki.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "collapsed": true,
        "id": "u_ZoILl_43lt",
        "outputId": "30eea385-5e00-4fff-89f7-f3271609bfc5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Page: Multi-agent system\\nSummary: A multi-agent system (MAS or \"self-organized system\") is a computerized system composed of multiple interacting intelligent agents. Multi-agent systems can solve problems that are difficult or impossible for an individual agent or a monolithic system to solve. Intelligence may include methodic, functional, procedural approaches, algorithmic search or reinforcement learning. With advancements in large language models (LLMs), LLM-based multi-agent systems have eme'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wiki.invoke(\"Agentic AI systems update\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzpdYqO5_zqG"
      },
      "source": [
        "#Tavily\n",
        "Real-time web search for AI agents\n",
        "(retrieve real-time information from the internet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ2VN3em6jBr",
        "outputId": "12304045-3c16-48c0-80d5-b8c2754eb148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tavily_search_results_json\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily = TavilySearchResults()\n",
        "print(tavily.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EMEdxO747hyE",
        "outputId": "4afb0ba7-2015-44f3-c478-842f6c258083"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'title': 'Best 5 Frameworks To Build Multi-Agent AI Applications - GetStream.io',\n",
              "  'url': 'https://getstream.io/blog/multiagent-ai-frameworks/',\n",
              "  'content': \"There are several ways to build an AI agent from scratch. Agents can be built in Python or using React and other technology stacks. However, agentic frameworks like Agno, OpenAI Swarm, LangGraph, Microsoft Autogen, CrewAI, Vertex AI, and Langflow provide tremendous benefits. These frameworks have pre-packaged tools and features to help you quickly build any AI assistant. [...] To learn more about these limitations, see LangChain's State of AI Agent—2024.\\nTop 5 Multi-Agent AI Frameworks\\nYou can use several Python frameworks to create and add agents to applications and services. These frameworks include no-code (visual AI agent builders), low-code, and medium-code tools. This section presents five leading Python-based agent builders you can choose depending on your enterprise's or business's needs.\\n1. Agno [...] You will see a response similar to the image below.\\nTo kick off your agent creation project with CrewAI, check out the Get Started and How-to guides.\\n4. Autogen\\nAutogen is an open-source framework for building agentic systems. You can use this framework to construct multi-agent collaborations and LLM workflows.\\nKey Features of Autogen\\nThe key features of Autogen include the following.\",\n",
              "  'score': 0.8036831},\n",
              " {'title': \"Microsoft's Agentic Frameworks: AutoGen and Semantic Kernel\",\n",
              "  'url': 'https://devblogs.microsoft.com/autogen/microsofts-agentic-frameworks-autogen-and-semantic-kernel/',\n",
              "  'content': 'Microsoft’s agentic AI frameworks, Semantic Kernel and AutoGen are deeply collaborating to provide the best-in-class agentic developer experience. With Semantic Kernel’s enterprise ready AI capabilities, customers can already use and get support for building agent applications and, moving forward, we’ll align the multi-agent runtime in AutoGen (called autogen-core) with Semantic Kernel, allowing customers to create enterprise-ready multi-agent solutions. [...] If you’re willing to harden and make AutoGen enterprise ready with your overall solution, then you can continue using it with community support only. Customers might choose this path if they have a need for complex agentic patterns that are not yet available in Semantic Kernel or any other product.\\nAre there any resources to help me get started with these frameworks?\\nYes, Microsoft provides resources for both frameworks:\\nSemantic Kernel: [...] Leveraging the complementary capabilities of Semantic Kernel and AutoGen allows developers to explore innovative patterns while ensuring stability in production environments. We encourage you to take advantage of these robust frameworks to realize your AI development goals. Stay tuned for more about how we’re building a pipeline to you bring your AutoGen agentic applications into Semantic Kernel! Thank you for being part of our community, and together, let’s drive the future of AI!\\n8\\n1\\n2',\n",
              "  'score': 0.78014404},\n",
              " {'title': 'Top 7 Frameworks for Building AI Agents in 2025 - Analytics Vidhya',\n",
              "  'url': 'https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/',\n",
              "  'content': 'AI agent frameworks are software platforms designed to simplify creating, deploying, and managing AI agents. These frameworks provide developers with pre-built components, abstractions, and tools that streamline the development of complex AI systems. By offering standardized approaches to common challenges in AI agent development, these frameworks enable developers to focus on the unique aspects of their applications rather than reinventing the wheel for each project.\\nKey Components of AI Agent [...] Artificial intelligence has seen a surge in AI agents—autonomous software entities that perceive environments, make decisions, and act to achieve goals. These agents, with advanced planning and reasoning capabilities, go beyond traditional reinforcement learning models. Building them requires AI agent frameworks. This article explores the top 7 frameworks for creating AI agents. Central to modern AI agents are agentic AI systems, which combine large language models (LLMs), tools, and prompts to [...] Accelerated Development: By providing pre-built components and best practices, these frameworks significantly reduce the time and effort required to create sophisticated AI agents.\\nStandardization: Frameworks promote consistent approaches to common challenges, facilitating collaboration and knowledge sharing within the AI community.\\nScalability: Many frameworks are designed to support the development of systems ranging from simple single-agent applications to complex multi-agent environments.',\n",
              "  'score': 0.7316155},\n",
              " {'title': 'Top 5 Agentic AI Frameworks to Watch in 2025 - Lekha Priya - Medium',\n",
              "  'url': 'https://lekha-bhan88.medium.com/top-5-agentic-ai-frameworks-to-watch-in-2025-9d51b2b652c0',\n",
              "  'content': 'Agentic AI frameworks like Microsoft AutoGen, LangChain, and CrewAI are laying the groundwork for a future where AI systems operate autonomously, adapt dynamically, and collaborate seamlessly. These tools are enabling developers to build solutions that are more robust, intelligent, and scalable than ever before.\\n💡 Want to stay ahead of the curve? Explore these frameworks and see how they can revolutionize your AI projects!\\nDid you find this article insightful? Don’t forget to: [...] https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/\\nThe evolution of Agentic AI is unlocking new frontiers in autonomous systems and intelligent agents. As we enter 2025, developers and enterprises are looking for frameworks that not only streamline AI workflows but also enable complex decision-making and collaboration. In this article, we’ll explore the top five Agentic AI frameworks that are set to transform the AI landscape in 2025.',\n",
              "  'score': 0.7060491},\n",
              " {'title': 'Top 5 Free AI Agent Frameworks - Botpress',\n",
              "  'url': 'https://botpress.com/blog/ai-agent-frameworks',\n",
              "  'content': 'Build Agentic Workflows\\nBuild custom Agentic Workflows\\nStart now\\nNo credit card required\\nWhat are AI Agent Frameworks?\\nAI agent frameworks are platforms, tools, or libraries designed to create autonomous agents that perceive input, process it using algorithms or LLMs, and take actions such as retrieving data, initiating workflows, or responding to customers. [...] These frameworks are the unsung heroes behind AI agents capable of doing it all: navigating complex workflows, solving real-world problems, and scaling effortlessly. Whether streamlining customer support, personalizing user experiences, or automating the mundane, AI agentic frameworks let you harness the power of cutting-edge LLMs (large language models) to create something extraordinary.',\n",
              "  'score': 0.69746524}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tavily.invoke(\"Provide me the frameworks of agentic ai applications\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r56-Yj5p8CMv"
      },
      "outputs": [],
      "source": [
        "tools = [arxiv, wiki, tavily]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wo6B2W-g85QL",
        "outputId": "78643dcc-8e3e-4696-d830-4a63e4a62cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.11/dist-packages (0.3.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.59)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.13.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain-groq) (24.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.10.18)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain-groq) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.49->langchain-groq) (2.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MmF5S1pAhTZ"
      },
      "source": [
        "#Large Language Model with tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDwru8mR8jSA"
      },
      "outputs": [],
      "source": [
        "## Initialization of LLM\n",
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(model=\"qwen-qwq-32b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CrxLQLJa9AqS",
        "outputId": "bb7e1b8c-a26f-4884-a2e8-a018e0b78d8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='\\n<think>\\nOkay, so the user is asking how agents and tools collaborate intelligently. Let me start by breaking this down. First, I need to understand what they mean by \"agents\" and \"tools.\" In the context of AI, agents are usually software systems that can act autonomously to some extent, like chatbots or personal assistants. Tools might be specific programs or APIs they use to perform tasks. \\n\\nI should probably start by defining both agents and tools to set the foundation. Agents are decision-making entities, right? They have goals and use perception and action to achieve them. Tools are the resources they use to perform tasks. So collaboration between them means that agents use tools effectively to reach their objectives. But how exactly does that work?\\n\\nMaybe I should think about different models or frameworks. There\\'s the idea of task decomposition, where a big task is split into smaller parts that each agent or tool can handle. Like, if an agent needs to book a flight, it might use a search tool to find flights and another tool to book it. That\\'s a simple example, but maybe more complex collaborations involve more coordination.\\n\\nThen there\\'s the aspect of communication between agents. Do they need a common language or protocol? Maybe something like message passing or shared data structures. Also, how do they decide which tool to use when? There must be some decision-making process or algorithm that evaluates the best tool for a specific subtask.\\n\\nI should consider different types of collaboration structures. Maybe centralized vs. decentralized. In a centralized system, there\\'s a master agent that coordinates all the others. Decentralized would be more like a swarm where each agent acts on local information. Then there\\'s the pipeline approach, where agents pass the output of one tool to another in sequence. \\n\\nWait, but the user asked for \"intelligent\" collaboration. So it\\'s not just any collaboration but one that\\'s smart. That probably involves learning and adaptability. Maybe agents can learn from past interactions to choose better tools next time. Reinforcement learning comes to mind here, where agents get feedback on their actions and adjust their strategies.\\n\\nAlso, there\\'s the aspect of error handling and adaptability. If a tool fails, the agent should be able to switch to a backup or find an alternative method. That requires some form of exception handling and maybe even problem-solving abilities. \\n\\nAnother point is interoperability. Tools might have different interfaces, so agents need ways to interface with them, maybe through APIs or adapters. Standardized protocols could help here. \\n\\nI should also think about real-world examples. Like in a customer service scenario, an agent might use a knowledge base tool to find information and then a CRM tool to update the customer\\'s record. Or in a research setting, agents might use data analysis tools to process information and then visualization tools to present it.\\n\\nWait, maybe I should outline the key components first before diving into examples. Components could include task decomposition, communication protocols, decision-making algorithms, learning mechanisms, error handling, and tool interfaces. \\n\\nAlso, considering coordination mechanisms like task queues or workflows. Maybe using something like a workflow engine that manages the flow between different tools and agents. \\n\\nWhat about the role of knowledge bases? Agents might need access to information to make informed tool choices. So, a knowledge graph or database could be part of the infrastructure enabling intelligent collaboration.\\n\\nI should also mention some challenges. Like ensuring that agents don\\'t duplicate efforts or have conflicting actions. That would require some form of conflict resolution or consensus algorithms. Also, security and access control when using different tools and data sources.\\n\\nHmm, maybe structuring the answer into sections like components, collaboration models, examples, and challenges. Let me see. The user might want a comprehensive explanation, so organizing it step by step would be best.\\n\\nStarting with defining agents and tools, then moving into how they interact. Then discussing different collaboration models like task-based, pipeline, etc. Then talking about the mechanisms like communication, decision-making, learning. Then examples and challenges. That seems logical.\\n\\nWait, but I should also think about the intelligence aspect. So, intelligence comes from the agents\\' ability to adapt, learn, and make optimal decisions. That means integrating machine learning and AI into their decision-making processes. For example, using ML models to predict which tool is best suited for a task based on historical data.\\n\\nAnother thought: the concept of a \"tool selection algorithm\" where the agent evaluates different tools based on criteria like efficiency, accuracy, or cost. Maybe using some scoring system or ranking to choose the best tool for the job.\\n\\nAlso, feedback loops are important. After using a tool, the agent can log the outcome and adjust future choices. That\\'s part of the learning process. Reinforcement learning could be applied here, where the agent gets rewards for successful outcomes.\\n\\nIn terms of communication, maybe using a common language like JSON or XML messages. Or more complex semantic frameworks so that agents can understand each other\\'s intents and data formats.\\n\\nWait, but how do agents coordinate without stepping on each other\\'s toes? Maybe using task allocation algorithms, like in multi-agent systems, where agents can bid on tasks or have roles assigned based on their capabilities.\\n\\nAlso, in some cases, agents might need to combine the results from multiple tools. For example, using data from a weather API and a traffic API to suggest the best route. So, integrating outputs from different tools into a coherent result.\\n\\nI should also consider scalability. As the number of agents and tools grows, the system might need to manage resources efficiently. Maybe a resource management layer that allocates tools based on availability and load.\\n\\nAnother point is the use of ontologies or schemas to represent the capabilities of tools and the requirements of tasks. This way, agents can reason about which tools are applicable. For instance, a tool\\'s ontology might state that it can process natural language queries, so the agent knows to use it for NLP tasks.\\n\\nI should also mention middleware or frameworks that facilitate this collaboration, like middleware systems or integration platforms that connect different tools and agents. Tools like Kubernetes for orchestration, or message brokers like RabbitMQ for communication between agents.\\n\\nExamples would help. Like in healthcare, agents might coordinate lab tests (tools) to diagnose a patient. In finance, agents could use various financial tools to optimize investments.\\n\\nWait, but I need to ensure that I cover both the technical aspects (how they communicate, protocols) and the decision-making intelligence (learning, adaptability).)\\n\\nMaybe the key elements are:\\n\\n1. Task decomposition and assignment\\n2. Communication protocols\\n3. Decision-making and tool selection algorithms\\n4. Learning and adaptation mechanisms\\n5. Error handling and resilience\\n6. Interoperability and standardization\\n7. Coordination and resource management\\n\\nPutting this all together in a structured way. Also, mentioning specific technologies or methods where applicable, like API integrations, ML models, etc.\\n\\nI should also address the intelligence part. Intelligence here refers to the agents\\' ability to make informed, adaptive decisions. So, the collaboration isn\\'t just procedural but involves reasoning and learning.\\n\\nHmm, maybe start with an overview, then break down the components, discuss collaboration models, talk about intelligence-enabling features, provide examples, and mention challenges. That should cover the question thoroughly.\\n\\nI need to make sure I don\\'t miss any key points. Let me check: the user asked how they collaborate intelligently. So the answer should explain both the methods of collaboration and the intelligent aspects (like learning, adaptability, optimization) that make the collaboration smart.\\n\\nAlright, I think I have a rough outline. Now, let me structure this into a coherent answer with clear sections and explanations.\\n</think>\\n\\nAgents and tools collaborate intelligently through a structured, adaptive, and coordinated process that leverages advanced algorithms, communication protocols, and learning mechanisms. Here\\'s a detailed breakdown of how this collaboration works:\\n\\n---\\n\\n### **1. Key Components of Intelligent Collaboration**\\n#### **a. Agents**\\n- **Definition**: Autonomous or semi-autonomous software entities designed to achieve specific goals (e.g., a chatbot, an inventory manager, or a data analysis engine).\\n- **Capabilities**: \\n  - **Perception**: Gather data (e.g., via sensors, APIs).\\n  - **Reasoning**: Make decisions based on rules, logic, or machine learning (ML).\\n  - **Action**: Execute tasks, modify their environment, or interact with tools.\\n\\n#### **b. Tools**\\n- **Definition**: Specialized programs, APIs, or services that perform specific tasks (e.g., a weather API, a machine learning model, or a database).\\n- **Capabilities**:\\n  - Execute predefined functions (e.g., image recognition, data analysis).\\n  - Provide outputs that agents can interpret and act upon.\\n\\n---\\n\\n### **2. Core Mechanisms for Intelligent Collaboration**\\n#### **a. Task Decomposition**\\n- **Break Down Tasks**: Agents decompose complex problems into subtasks. For example:\\n  - A travel agent might split \"plan a trip\" into finding flights, booking hotels, and suggesting activities.\\n- **Assign Subtasks to Tools**: Each subtask is assigned to the most appropriate tool (e.g., a flight-booking API for flights).\\n\\n#### **b. Communication Protocols**\\n- **Standardized Interfaces**: Tools provide APIs, web services, or microservices for agents to interact with them.\\n- **Common Language**: Agents communicate via structured formats (JSON, XML) or semantic frameworks (e.g., ontologies) to ensure mutual understanding.\\n- **Message Passing**: Tools send outputs (e.g., data, error codes) back to agents for further decision-making.\\n\\n#### **c. Decision-Making & Tool Selection**\\n- **Tool Selection Algorithms**: Agents evaluate tools based on:\\n  - **Performance metrics** (speed, accuracy).\\n  - **Relevance** (does the tool match the task\\'s requirements?).\\n  - **Cost constraints** (computational, financial).\\n- **Adaptive Learning**: Agents use historical data or ML models to predict the best tool for future tasks (e.g., a recommendation system that learns user preferences).\\n\\n#### **d. Learning and Adaptation**\\n- **Reinforcement Learning (RL)**: Agents receive feedback (e.g., success/failure of a tool) to optimize future choices.\\n- **Continuous Improvement**: Agents update their strategies over time as tools evolve or new tools become available.\\n- **Error Handling**: If a tool fails, agents can reroute tasks to alternatives (e.g., if a payment gateway is down, switch to a backup).\\n\\n#### **e. Coordination and Orchestration**\\n- **Workflow Engines**: Systems like Apache Airflow or Kubernetes orchestrate the sequence of tools and agents (e.g., a pipeline: data ingestion → preprocessing → ML model → visualization).\\n- **Task Queues**: Tools like Celery or message brokers (e.g., Kafka) manage task distribution and parallel processing.\\n- **Conflict Resolution**: Algorithms resolve conflicts (e.g., two agents requesting the same resource) using priority rules or negotiation protocols.\\n\\n#### **f. Interoperability**\\n- **APIs and Adapters**: Tools expose APIs for agents to interact with them. Adapters convert outputs into a common format (e.g., CSV to JSON).\\n- **Middleware**: Platforms like Zapier or Microsoft Power Automate connect disparate tools and agents.\\n\\n---\\n\\n### **3. Collaboration Models**\\n#### **a. Task-Based Collaboration**\\n- **Example**: A customer service agent uses a knowledge base tool to answer queries and a CRM tool to update customer records.\\n- **Process**: Agents break down the user’s request into subtasks and route each to the appropriate tool.\\n\\n#### **b. Pipeline-Based Collaboration**\\n- **Example**: A data science pipeline where:\\n  1. Tool A cleans data.\\n  2. Tool B processes it with an ML model.\\n  3. Tool C visualizes the results.\\n- **Process**: Agents orchestrate the sequence and handle handoffs between tools.\\n\\n#### **c. Decentralized Coordination (Swarm Intelligence)**\\n- **Example**: A swarm of agents collaboratively solve a problem (e.g., optimizing a supply chain).\\n- **Process**: Agents communicate via a decentralized network, share partial solutions, and combine results (e.g., consensus-based algorithms).\\n\\n#### **d. Centralized Coordination**\\n- **Example**: A central \"manager\" agent oversees multiple sub-agents and tools (e.g., a traffic control system managing drones and sensors).\\n- **Process**: The central agent delegates tasks and aggregates results.\\n\\n---\\n\\n### **4. Intelligence-Enabling Features**\\n#### **a. Machine Learning Integration**\\n- **Tool Optimization**: Agents use ML to predict tool performance (e.g., choosing the fastest API for real-time data).\\n- **Dynamic Adaptation**: Agents learn from past interactions to improve future decisions (e.g., a recommendation system adjusting based on user feedback).\\n\\n#### **b. Knowledge Representation**\\n- **Ontologies/Schemas**: Shared knowledge graphs define tool capabilities and task requirements (e.g., \"Tool X can process images, but only for JPEG files\").\\n- **Context Awareness**: Agents use contextual data (e.g., user location, time) to select tools (e.g., using a localized weather API during a storm).\\n\\n#### **c. Feedback Loops**\\n- **Performance Monitoring**: Agents track tool efficiency and user satisfaction.\\n- **Continuous Improvement**: Feedback is used to refine tool selection and workflows (e.g., replacing a slow API).\\n\\n---\\n\\n### **5. Real-World Examples**\\n#### **a. Healthcare Diagnostics**\\n- **Scenario**: Diagnosing a patient.\\n- **Collaboration**:\\n  - Agent A uses a symptom-checker tool to gather patient data.\\n  - Agent B uses a medical database to cross-reference symptoms.\\n  - Agent C coordinates lab tests via diagnostic tools and synthesizes results for a diagnosis.\\n\\n#### **b. E-commerce Recommendation Systems**\\n- **Scenario**: Personalized product suggestions.\\n- **Collaboration**:\\n  - Agent A collects user data (clicks, purchases).\\n  - Tool 1 (ML model) processes data to predict preferences.\\n  - Agent B uses a recommendation engine tool to generate suggestions.\\n\\n#### **c. Autonomous Vehicles**\\n- **Scenario**: Navigating traffic.\\n- **Collaboration**:\\n  - Sensors (tools) collect real-time data (e.g., LiDAR, GPS).\\n  - Agents process data, decide on steering, acceleration, and communicate with other vehicles via V2X (vehicle-to-everything) tools.\\n\\n---\\n\\n### **6. Key Challenges**\\n- **Complexity**: Managing interactions in large-scale systems with many agents and tools.\\n- **Latency and Reliability**: Ensuring real-time responses and handling tool failures gracefully.\\n- **Security**: Protecting data flow between agents and tools (e.g., encrypting API calls).\\n- **Scalability**: Ensuring the system can grow without bottlenecks.\\n\\n---\\n\\n### **7. Technologies Enabling Intelligent Collaboration**\\n- **APIs and Microservices**: Tools expose functionality via APIs for modular integration.\\n- **Orchestration Tools**: Kubernetes, Apache Airflow, or cloud-based orchestrators.\\n- **ML Frameworks**: TensorFlow, PyTorch for adaptive decision-making.\\n- **Knowledge Graphs**: Ontologies (e.g., OWL) for semantic interoperability.\\n- **Blockchain**: For secure, decentralized coordination in trustless environments.\\n\\n---\\n\\n### **8. Future Directions**\\n- **Autonomous Systems**: Agents increasingly using generative AI to invent new workflows.\\n- **Edge Computing**: Tools and agents operating at the edge for real-time processing (e.g., IoT devices).\\n- **Explainable AI (XAI)**: Ensuring agents can justify their tool choices to users.\\n\\n---\\n\\n### **Summary**\\nIntelligent collaboration between agents and tools is achieved through:\\n- **Task-oriented decomposition** of problems into manageable subtasks.\\n- **Adaptive decision-making** via AI/ML to select the best tools dynamically.\\n- **Seamless communication** via APIs, middleware, and standardized protocols.\\n- **Continuous learning** to improve efficiency and resilience over time.\\n\\nThis framework enables systems to solve complex, real-world problems efficiently and adaptively, mimicking human-like reasoning in distributed environments.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 3302, 'prompt_tokens': 19, 'total_tokens': 3321, 'completion_time': 8.034962399, 'prompt_time': 0.003384325, 'queue_time': 0.483287507, 'total_time': 8.038346724}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_512a3da6bb', 'finish_reason': 'stop', 'logprobs': None}, id='run--d4ebf10e-9ddf-4608-adb9-44d1c9a6603b-0', usage_metadata={'input_tokens': 19, 'output_tokens': 3302, 'total_tokens': 3321})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"How do agents and tools collaborate intelligently?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnj6IPhm9odS"
      },
      "outputs": [],
      "source": [
        "llm_with_tools = llm.bind_tools(tools=tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw-JEOMT-kFR",
        "outputId": "4611b268-3c3d-4306-f450-9c8f0779d651"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cd6f', 'function': {'arguments': '{\"query\": \"recent news on AI\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 188, 'prompt_tokens': 355, 'total_tokens': 543, 'completion_time': 0.471734038, 'prompt_time': 0.038723173, 'queue_time': 0.5527038870000001, 'total_time': 0.510457211}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_1e88ca32eb', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bace47ac-6e5a-4391-9637-634bdaa1fe30-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'recent news on AI'}, 'id': 'call_cd6f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 355, 'output_tokens': 188, 'total_tokens': 543})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_with_tools.invoke(\"What is the recent news on AI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSS9GylXBRzO"
      },
      "source": [
        "#Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaXWFgMN-s3F"
      },
      "outputs": [],
      "source": [
        "# State Schema\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import AnyMessage # Human message or AI message\n",
        "from typing import Annotated # Labelling\n",
        "from langgraph.graph.message import add_messages # Reducers in langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-poyzoSC9xh"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw4380IQDu1-"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.prebuilt import tools_condition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi3FxCuHEaEY",
        "outputId": "d6322544-3446-4777-965f-1c061a305b9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78c405423a10>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tool_calling_llm(state:State):\n",
        "  return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Build Graph\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
        "builder.add_node(\"tools\", ToolNode(tools))\n",
        "\n",
        "# Edges\n",
        "builder.add_edge(START, \"tool_calling_llm\")\n",
        "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
        "builder.add_edge(\"tools\", END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "bGpPKEIbFeCe",
        "outputId": "29be0b6d-8f96-49ab-dbb3-b9ce1a5800eb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graph = builder.compile()\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uKKeOxhIl3D"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdkdUKVyGhIk",
        "outputId": "3b8aeb51-b00e-49bc-af73-01a780c48950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "1706.03762\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  arxiv (call_8p9n)\n",
            " Call ID: call_8p9n\n",
            "  Args:\n",
            "    query: 1706.03762\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: arxiv\n",
            "\n",
            "Published: 2023-08-02\n",
            "Title: Attention Is All You Need\n",
            "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
            "Summary: The dominant sequence transduction models are based on complex recurrent or\n",
            "convolutional neural networks in an encoder-decoder configuration. The best\n",
            "performing models also connect the encoder and decoder through an attention\n",
            "mechanism. We propose a new simple network architecture, the Transformer, base\n"
          ]
        }
      ],
      "source": [
        "messages = graph.invoke({\"messages\":HumanMessage(content=\"1706.03762\")})\n",
        "for m in messages['messages']:\n",
        "  m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aaf32xGHvsO",
        "outputId": "b0abd629-10c9-45fd-b7a4-ab49feba004d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hey, my name is Shayan, I am an AI Engineer\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Shayan! Nice to meet you. It's great that you're an AI Engineer—what kind of projects are you currently working on or interested in within the field of AI?\n"
          ]
        }
      ],
      "source": [
        "messages = graph.invoke({\"messages\":HumanMessage(content=\"Hey, my name is Shayan, I am an AI Engineer\")})\n",
        "for m in messages['messages']:\n",
        "  m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW_WAKG3JLZn",
        "outputId": "b5785c86-96c9-42d4-e69a-99a5e85b879d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I am currently working on Agentic AI Applications\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  arxiv (call_0qs8)\n",
            " Call ID: call_0qs8\n",
            "  Args:\n",
            "    query: agentic AI applications autonomous intelligent agents\n",
            "  tavily_search_results_json (call_pbr7)\n",
            " Call ID: call_pbr7\n",
            "  Args:\n",
            "    query: latest developments in agentic AI applications 2023\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: arxiv\n",
            "\n",
            "Published: 2024-10-21\n",
            "Title: Voice-Enabled AI Agents can Perform Common Scams\n",
            "Authors: Richard Fang, Dylan Bowman, Daniel Kang\n",
            "Summary: Recent advances in multi-modal, highly capable LLMs have enabled\n",
            "voice-enabled AI agents. These agents are enabling new applications, such as\n",
            "voice-enabled autonomous customer service. However, with all AI capabilities,\n",
            "these new capabilities have the potential for dual use.\n",
            "  In this work, we show that voice-enabled AI agents can perform the actions\n",
            "necessary t\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: tavily_search_results_json\n",
            "\n",
            "[{\"title\": \"The Rise of Agentic AI: What Every Technology Leader Needs to Know\", \"url\": \"https://www.linkedin.com/pulse/rise-agentic-ai-what-every-technology-leader-needs-know-wxnpf\", \"content\": \"According to Gartner, by 2026, over 60% of enterprise-level AI applications will feature agentic capabilities, up from less than 10% in 2023.\", \"score\": 0.7644879}, {\"title\": \"Agentic AI: Enhancing Enterprise Workflows in 2025\", \"url\": \"https://www.willowtreeapps.com/insights/agentic-ai-enhancing-workflows\", \"content\": \"Over the last few years, implementing enterprise AI has felt like building a skyscraper while the blueprints are continuously being redrawn. The rapid rise of ChatGPT in early 2023 thrust generative AI into the spotlight, prompting businesses to reconsider their digital strategies. As we moved through 2024, the initial hype gave way to a more pragmatic approach, with organizations seeking tangible ways to safely and securely integrate AI into their operations. Now, as we venture into 2025, a [...] 2024 saw the emergence of Retrieval Augmented Generation (RAG), a significant advancement that enhanced the capabilities of LLMs. RAG allows AI to access and summarize relevant, up-to-date information beyond its initial training data. This development improved the accuracy of AI outputs and enhanced more sophisticated applications, such as AI copilots. An everyday use case for copilots is in coding, where a human programmer receives notifications in real-time with suggestions to improve the [...] This agentic AI is capable of autonomous decision-making and complex task execution with minimal human oversight. At CES 2025, Nvidia CEO Jensen Huang declared that AI agents represent a multi-trillion dollar opportunity for businesses as the new technology moves from concept to practical application. This shift promises to reshape how enterprises use workflows across all sectors.\", \"score\": 0.73868835}, {\"title\": \"The Next “Next Big Thing”: Agentic AI's Opportunities and Risks\", \"url\": \"https://scet.berkeley.edu/the-next-next-big-thing-agentic-ais-opportunities-and-risks/\", \"content\": \"The learning module in agentic AI systems enable continuous adaptation, decision-making, and learning in response to changing environments. These modules are integrated at various points within an agentic AI system, depending on the specific tasks and goals.  Reflection (Madaan et al. 2023, Shinn et al. 2023, Gou et al. 2023) is an essential aspect of the learning module, allowing an agentic AI system to review its actions and decisions to enhance future performance. This process, closely tied [...] The learning module in agentic AI systems enable continuous adaptation, decision-making, and learning in response to changing environments. These modules are integrated at various points within an agentic AI system, depending on the specific tasks and goals.  Reflection (Madaan et al. 2023, Shinn et al. 2023, Gou et al. 2023) is an essential aspect of the learning module, allowing an agentic AI system to review its actions and decisions to enhance future performance. This process, closely tied [...] The learning module in agentic AI systems enable continuous adaptation, decision-making, and learning in response to changing environments. These modules are integrated at various points within an agentic AI system, depending on the specific tasks and goals.  Reflection (Madaan et al. 2023, Shinn et al. 2023, Gou et al. 2023) is an essential aspect of the learning module, allowing an agentic AI system to review its actions and decisions to enhance future performance. This process, closely tied\", \"score\": 0.7327644}, {\"title\": \"Agentic AI: The new frontier in AI evolution | Deloitte Luxembourg\", \"url\": \"https://www.deloitte.com/lu/en/our-thinking/future-of-advice/agentic-ai-the-new-frontier-in-ai-evolution.html\", \"content\": \"Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Processing Systems.\\n\\nVaswani, A., et al. (2017). Attention is All You Need. In Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS 2017).\\n\\nVipra, J., & West, S. M. (2023). Computational Power and AI. AI Now Institute. [...] Wei, J., et al. (2023). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.\\n\\nGet in touch\\n\\nRonan Vander Elst\\n\\nNicolas Griedlich\\n\\nDid you find this useful?\\n\\nThanks for your feedback\\n\\nYour feedback is important to us\\n\\nTo tell us what you think, please update your settings to accept analytics and performance cookies.\\n\\nLet's connect\\n\\n\\n\\n\\n\\n\\n\\nFollow us [...] The fast evolution of multi-agent AI systems is transforming how organizations address challenges and streamline processes. The commercial availability of language models, advanced agent ecosystems, and supportive frameworks are driving rapid advancements in Agentic AI.\", \"score\": 0.63777614}, {\"title\": \"[PDF] Agentic AI – the new frontier in GenAI - PwC\", \"url\": \"https://www.pwc.com/m1/en/publications/documents/2024/agentic-ai-the-new-frontier-in-genai-an-executive-playbook.pdf\", \"content\": \"impact, with estimates indicating that it could contribute between $2.6 trillion and $4.4 trillion annually to global GDP across various industries by 2030. In speciﬁc sectors, such as energy, investments in GenAI are expected to triple, from $40 billion in 2023 to over $140 billion by the end of the decade. This surge in investment reﬂects the transformative potential of GenAI, particularly in enhancing productivity, streamlining business processes, and reshaping value chains across [...] ●AI Models: In-house-developed multimodal foundation model ●Platforms: Multi-modal integration of omics, text, clinical trials, small molecule properties, and disease targets23 ●Tools: Transformer-based, in-house-trained AI model and platform Financial impact: ●Cost Reduction: 35% nine-month ROI in an investment application ●Time Eﬃciency: Reduced drug development time Non-ﬁnancial beneﬁts: ●Accelerated drug discovery and clinical trials process ●79% accuracy for clinical trials Legal: Hogan [...] Prediction of Clinical Trials Outcomes Based on Target Choice and Clinical Trial Design with Multi‐Modal Artiﬁcial Intelligence - Aliper - 2023 - Clinical Pharmacology & Therapeutics 24.\\nHogan Lovells Enhances Transactional Services with Kira 25.\\nThe Total Economic Impact™ Of Coupa For Source-To-Pay 26.\\nRethinking device management internally at Microsoft with AI - Inside Track Blog 27.\\nSalesforce Einstein AI Solutions 28.\\nLangChain Academy 29.\\nAutoGen 30.\\nCrewAI 31.\\nAutoGPT 32.\", \"score\": 0.63288915}]\n"
          ]
        }
      ],
      "source": [
        "messages = graph.invoke({\"messages\":HumanMessage(content=\"I am currently working on Agentic AI Applications\")})\n",
        "for m in messages['messages']:\n",
        "  m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25D9Q3WeKNsZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
